{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "import jpholiday\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics import tsaplots\n",
    "# from optuna.integration import lightgbm as lgb\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import  log_loss\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from datetime import date, timedelta\n",
    "import sklearn.metrics\n",
    "import optuna \n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas_profiling as pdp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基準モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = '/Users/atsushisato/git_clone/ai_quest_season2/data/'\n",
    "\n",
    "train_data = pd.read_csv(FILE_PATH + 'external/train.csv').rename(columns={'顧客ID':'uuid', 'クーポンID':'coupon_id', 'クーポン利用':'coupon_use_result'})\n",
    "test_data = pd.read_csv(FILE_PATH + 'external/test.csv').rename(columns={'顧客ID':'uuid', 'クーポンID':'coupon_id'})\n",
    "customer_df = pd.read_csv(FILE_PATH + 'interim/customer_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徴量作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#特徴量作成関数（trainとtestで異なる処理が可能）\n",
    "def create_feature_separate(dataframe):\n",
    "    # issue 9/10 カテゴリ変数の数値変換 \n",
    "    dataframe = category_to_int_conversion(dataframe)\n",
    "    \n",
    "    # issue 11 カテゴリ別商品単価\n",
    "    dataframe['unit_price_category'] = dataframe.apply(lambda x: \n",
    "                                unit_price_category(x['purchase_product_num'], x['coupon_use'], x['purchase_price']),axis=1)\n",
    "    # issue 16 総購入商品の平均\n",
    "    dataframe['purchase_price_average'] = dataframe.apply(lambda x: \n",
    "                                purchase_price_average(x['all_purchase_price'], x['visits_frequency']),axis=1)   \n",
    "    # issue 20 平均来店周期\n",
    "    dataframe['visit_cycle'] = dataframe.apply(lambda x:\n",
    "                                visit_cycle(x['visits_frequency'], x['pass_days']),axis=1)\n",
    "    # issue 21 経過日数と来店頻度の比較\n",
    "    dataframe['visit_cycle_flg'] = dataframe.apply(lambda x: \n",
    "                                visit_cycle_flg(x['visit_cycle'], x['pass_days']),axis=1) \n",
    "    # issue 22 総購入金額に占めるカテゴリ別の購入金額比率\n",
    "    dataframe['ratio_category'] = dataframe.apply(lambda x:\n",
    "                                ratio_category(x['all_purchase_price'], x['purchase_price']),axis=1)\n",
    "    # issue 23 大人の数\n",
    "    dataframe['adult_num'] = dataframe['fammily_num'] - dataframe['child_num']\n",
    "    \n",
    "    # issue 24 カテゴリ別平均購入金額\n",
    "    dataframe['purchase_price_category_average'] = dataframe.apply(lambda x:\n",
    "                                purchase_price_category_average(x['purchase_price'], x['purchase_product_num'],x['coupon_use']),axis=1)\n",
    "    # issue 28 家族1人あたりの総購入金額\n",
    "    dataframe['purchase_price_1person'] = dataframe.apply(lambda x:\n",
    "                                purchase_price_1person(x['all_purchase_price'], x['fammily_num']),axis=1)\n",
    "    # issue 29 1日あたりの購入金額\n",
    "    dataframe['purchase_price_1day'] = dataframe.apply(lambda x :\n",
    "                                purchase_price_1day(x['all_purchase_price'], x['pass_days']),axis=1)\n",
    "    \n",
    "    \n",
    "    dataframe = dataframe.drop(['category_id', 'house_flg', 'marry_flg', 'age', 'visit_cycle_flg', 'category_id'],axis=1)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===================================================================================\n",
    "#特徴量作成関数\n",
    "# issue 9/10 カテゴリ変数の数値変換    \n",
    "def category_to_int_conversion(dataframe):\n",
    "    marry_dict = {'無回答':None, '独身':0, '既婚':1}\n",
    "    dataframe['marry_flg'] = dataframe['marry'].apply(lambda x: marry_dict.get(x))\n",
    "    \n",
    "    dataframe['age'] = dataframe['age_range'].apply(lambda x: int(x[:2]))\n",
    "    dataframe['category_id'] = dataframe['category_id'].apply(lambda x: int(x[1:]))\n",
    "    \n",
    "    dataframe = dataframe.drop(['age_range','marry','category'],axis=1)\n",
    "    return dataframe\n",
    "\n",
    "# issue 11 カテゴリ別商品単価\n",
    "def unit_price_category(product_num, coupon_use, price):\n",
    "    if coupon_use != 0:\n",
    "        price = price + abs(coupon_use)\n",
    "    \n",
    "    if price != 0:\n",
    "        return int(price / product_num)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# issue 16 総購入商品の平均\n",
    "def purchase_price_average(all_purchase_price, visits_frequency):\n",
    "    if (all_purchase_price != 0) & (visits_frequency != 0):\n",
    "        one_purchase_price =  int(all_purchase_price / visits_frequency)            \n",
    "    else:\n",
    "        one_purchase_price =  0\n",
    "    return one_purchase_price\n",
    "\n",
    "# issue 20 平均来店周期\n",
    "def visit_cycle(visits_frequency, pass_days):\n",
    "    all_days = 60\n",
    "    if visits_frequency != 0:\n",
    "        cycle = int((all_days - pass_days) / visits_frequency)\n",
    "    else:\n",
    "        cycle = 0\n",
    "    return cycle\n",
    "\n",
    "# issue 21 経過日数と来店頻度の比較\n",
    "def visit_cycle_flg(visit_cycle, pass_days):\n",
    "    if visit_cycle <= pass_days:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# issue 22 総購入金額に占めるカテゴリ別の購入金額比率\n",
    "def ratio_category(all_purchase_price, purchase_price):\n",
    "    if purchase_price != 0:\n",
    "        ratio = purchase_price / all_purchase_price\n",
    "    else:\n",
    "        ratio = 0\n",
    "    return ratio\n",
    "\n",
    "# issue 24 カテゴリ別平均購入金額\n",
    "def purchase_price_category_average(purchase_price, purchase_product_num, coupon_use):\n",
    "    if purchase_product_num != 0:\n",
    "        purchase_price = purchase_price + abs(coupon_use)\n",
    "        average_purchase = int(purchase_price / purchase_product_num)\n",
    "    else:\n",
    "        average_purchase = 0\n",
    "    return average_purchase\n",
    "    \n",
    "# issue 28 家族1人あたりの総購入金額\n",
    "def purchase_price_1person(all_purchase_price, fammily_num):\n",
    "    if all_purchase_price != 0:\n",
    "        return int(all_purchase_price / fammily_num)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# issue 29 1日あたりの購入金額\n",
    "def purchase_price_1day(all_purchase_price, pass_days):\n",
    "    if all_purchase_price != 0:\n",
    "        all_days = 60\n",
    "        use_days = all_days - pass_days + 1\n",
    "        return int(all_purchase_price / use_days)\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# issue 19 欠損値削除（購入履歴はあるが来店履歴がないuuid）\n",
    "def drop_missing_value(dataframe):\n",
    "    drop_uuid = dataframe.query(\"(visits_frequency ==0 )& (all_purchase_price != 0)\")['uuid'].unique()\n",
    "    dataframe = dataframe.query(\"uuid not in @drop_uuid\") \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataとtest_dataの特徴量作成\n",
    "train_data = pd.merge(train_data, customer_df, on=['uuid', 'coupon_id'],how='inner')\n",
    "test_data = pd.merge(test_data, customer_df, on=['uuid', 'coupon_id'],how='inner')\n",
    "\n",
    "#特徴量作成（train_dataとtest_dataで異なる処理が可能）\n",
    "train_data = create_feature_separate(train_data)\n",
    "test_data = create_feature_separate(test_data)\n",
    "train_data = drop_missing_value(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdp.ProfileReport(train_data.query(\"coupon_use_result == 1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adult_num',\n",
       " 'all_purchase_price',\n",
       " 'child_num',\n",
       " 'coupon_id',\n",
       " 'coupon_use',\n",
       " 'coupon_use_result',\n",
       " 'fammily_num',\n",
       " 'income',\n",
       " 'pass_days',\n",
       " 'purchase_num',\n",
       " 'purchase_price',\n",
       " 'purchase_price_1day',\n",
       " 'purchase_price_1person',\n",
       " 'purchase_price_average',\n",
       " 'purchase_price_category_average',\n",
       " 'purchase_product_num',\n",
       " 'ratio_category',\n",
       " 'unit_price_category',\n",
       " 'uuid',\n",
       " 'visit_cycle',\n",
       " 'visits_frequency']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(train_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_data.drop(['coupon_use_result','uuid'], axis=1)\n",
    "train_y = train_data[['coupon_use_result']]\n",
    "\n",
    "val_size = 4\n",
    "uuid_num = train_data['uuid'].nunique()\n",
    "train_uuid = int((uuid_num/val_size)*(val_size-1))\n",
    "filter_idx = (train_uuid*11)-1\n",
    "tr_x, va_x = train_x.iloc[:filter_idx], train_x.iloc[filter_idx:]\n",
    "tr_y, va_y = train_y.iloc[:filter_idx], train_y.iloc[filter_idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(tr_x, label=tr_y)\n",
    "dvalid = xgb.DMatrix(va_x, label=va_y)\n",
    "dtest = xgb.DMatrix(test_data.drop('uuid',axis=1))\n",
    "\n",
    "num_round = 1000\n",
    "# ハイパーパラメータの設定\n",
    "score_dict = {}\n",
    "# for i in range(100):\n",
    "params = {'objective': 'binary:logistic', \n",
    "          'eval_metric':'logloss',\n",
    "          'eta': 0.01,\n",
    "          'gamma': 0.0,\n",
    "          'alpha': 0.0,\n",
    "          'lambda': 1.0,\n",
    "          'min_child_weight': 8,\n",
    "          'max_depth': 6,\n",
    "          'subsample': 1.0,\n",
    "          'colsample_bytree': 0.8,\n",
    "          'random_state': 27,\n",
    "        }\n",
    "\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "model = xgb.train(params, \n",
    "                  dtrain, \n",
    "                  num_round, \n",
    "                  evals=watchlist,\n",
    "                  early_stopping_rounds=100,\n",
    "                  verbose_eval=False\n",
    "                 )\n",
    "\n",
    "va_pred = model.predict(dvalid)\n",
    "score = log_loss(va_y, va_pred)\n",
    "#     score_dict[i] = score\n",
    "    \n",
    "pred = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04931323879549301"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_score(pred):\n",
    "    if pred <= 0.0056:\n",
    "        pred = 0\n",
    "    elif pred >= 0.9944:\n",
    "        pred = 1\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.3816811740398407\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>coupon_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uuid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064750</td>\n",
       "      <td>0.006409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018686</td>\n",
       "      <td>0.012669</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.026029</td>\n",
       "      <td>0.027812</td>\n",
       "      <td>0.043240</td>\n",
       "      <td>0.030989</td>\n",
       "      <td>0.030804</td>\n",
       "      <td>0.381681</td>\n",
       "      <td>0.259802</td>\n",
       "      <td>0.027671</td>\n",
       "      <td>0.029766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013437</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014264</td>\n",
       "      <td>0.007093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0.022680</td>\n",
       "      <td>0.022931</td>\n",
       "      <td>0.018737</td>\n",
       "      <td>0.023165</td>\n",
       "      <td>0.025431</td>\n",
       "      <td>0.017372</td>\n",
       "      <td>0.023424</td>\n",
       "      <td>0.138719</td>\n",
       "      <td>0.020328</td>\n",
       "      <td>0.024063</td>\n",
       "      <td>0.024063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026817</td>\n",
       "      <td>0.005874</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>0.010199</td>\n",
       "      <td>0.006210</td>\n",
       "      <td>0.006055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019989</td>\n",
       "      <td>0.030289</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>0.006287</td>\n",
       "      <td>0.005846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0.013801</td>\n",
       "      <td>0.016852</td>\n",
       "      <td>0.014602</td>\n",
       "      <td>0.015778</td>\n",
       "      <td>0.038051</td>\n",
       "      <td>0.014353</td>\n",
       "      <td>0.013637</td>\n",
       "      <td>0.290274</td>\n",
       "      <td>0.082430</td>\n",
       "      <td>0.016855</td>\n",
       "      <td>0.015604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>0.007007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008668</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "coupon_id        1         2         3         4         5         6   \\\n",
       "uuid                                                                    \n",
       "357        0.000000  0.000000  0.000000  0.000000  0.013146  0.000000   \n",
       "358        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "359        0.026600  0.026600  0.026029  0.027812  0.043240  0.030989   \n",
       "360        0.000000  0.013437  0.000000  0.000000  0.000000  0.000000   \n",
       "361        0.022680  0.022931  0.018737  0.023165  0.025431  0.017372   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "708        0.000000  0.000000  0.000000  0.005995  0.000000  0.000000   \n",
       "709        0.010199  0.006210  0.006055  0.000000  0.000000  0.000000   \n",
       "710        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "711        0.013801  0.016852  0.014602  0.015778  0.038051  0.014353   \n",
       "712        0.007007  0.000000  0.000000  0.008668  0.000000  0.000000   \n",
       "\n",
       "coupon_id        7         8         9         10        11  \n",
       "uuid                                                         \n",
       "357        0.000000  0.064750  0.006409  0.000000  0.000000  \n",
       "358        0.000000  0.018686  0.012669  0.000000  0.000000  \n",
       "359        0.030804  0.381681  0.259802  0.027671  0.029766  \n",
       "360        0.000000  0.014264  0.007093  0.000000  0.000000  \n",
       "361        0.023424  0.138719  0.020328  0.024063  0.024063  \n",
       "...             ...       ...       ...       ...       ...  \n",
       "708        0.000000  0.026817  0.005874  0.000000  0.008146  \n",
       "709        0.019989  0.030289  0.008368  0.006287  0.005846  \n",
       "710        0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "711        0.013637  0.290274  0.082430  0.016855  0.015604  \n",
       "712        0.000000  0.022197  0.000000  0.000000  0.000000  \n",
       "\n",
       "[356 rows x 11 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(dtest)\n",
    "pred = pd.Series(pred, name='pred')\n",
    "pred = pred.apply(lambda x: round_score(x))\n",
    "print(pred.min(), pred.max())\n",
    "\n",
    "result = test_data.join(pred)[['uuid', 'coupon_id', 'pred']]\n",
    "result = result.pivot(index='uuid', columns='coupon_id', values='pred')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================\n",
    "#LightGBMによるモデル作成\n",
    "\n",
    "# score_dict = dict()\n",
    "# for i in range(100):\n",
    "params = {'objective': 'binary',\n",
    "         'metric': 'binary_logloss',\n",
    "         'seed': 54,\n",
    "         'lambda_l1': 0.059894240326589916,\n",
    "         'lambda_l2': 0.000010302168677111394,\n",
    "         'num_leaves': 382,\n",
    "         'feature_fraction': 0.9760627682340816,\n",
    "         'bagging_fraction': 0.957495412018543,\n",
    "         'bagging_freq': 7,\n",
    "         'min_child_samples': 14\n",
    "        }\n",
    "\n",
    "num_round =1000\n",
    "lgb_train = lgb.Dataset(tr_x, tr_y)\n",
    "lgb_eval = lgb.Dataset(va_x, va_y)\n",
    "\n",
    "model = lgb.train(params, \n",
    "              lgb_train,\n",
    "              verbose_eval=False,  # 50イテレーション毎に学習結果出力\n",
    "              num_boost_round=num_round, \n",
    "              early_stopping_rounds=100,\n",
    "              valid_names=['train', 'valid'], \n",
    "              valid_sets=[lgb_train, lgb_eval]\n",
    "             )\n",
    "\n",
    "va_pred = model.predict(va_x)\n",
    "score = log_loss(va_y, va_pred)\n",
    "#     score_dict[i] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.05011535679327886,\n",
       " 1: 0.05162192857016291,\n",
       " 2: 0.05083632669257753,\n",
       " 3: 0.05242817167773983,\n",
       " 4: 0.05135279743825156,\n",
       " 5: 0.05277221671814219,\n",
       " 6: 0.05378655496831985,\n",
       " 7: 0.05387897511294902,\n",
       " 8: 0.053047650936858204,\n",
       " 9: 0.050457607604724314,\n",
       " 10: 0.04995294142955738,\n",
       " 11: 0.053573450378349305,\n",
       " 12: 0.05361779806410574,\n",
       " 13: 0.05217438555128535,\n",
       " 14: 0.052495208752044914,\n",
       " 15: 0.0523280409395143,\n",
       " 16: 0.05243528317854127,\n",
       " 17: 0.051263542649004054,\n",
       " 18: 0.052049282520127645,\n",
       " 19: 0.05236701829825393,\n",
       " 20: 0.05218791965766804,\n",
       " 21: 0.05382136721234172,\n",
       " 22: 0.05467355395026898,\n",
       " 23: 0.05270543342676882,\n",
       " 24: 0.05233456246716357,\n",
       " 25: 0.05535735358949069,\n",
       " 26: 0.050166247461798145,\n",
       " 27: 0.05371339751552648,\n",
       " 28: 0.050101566450748314,\n",
       " 29: 0.05173472661414455,\n",
       " 30: 0.05128763280115434,\n",
       " 31: 0.052207745615865,\n",
       " 32: 0.05128713632334726,\n",
       " 33: 0.0493571882989601,\n",
       " 34: 0.051992100678358404,\n",
       " 35: 0.04950157072566798,\n",
       " 36: 0.05233519688890929,\n",
       " 37: 0.05267518596972037,\n",
       " 38: 0.05199194326898963,\n",
       " 39: 0.05171629698461303,\n",
       " 40: 0.052285669185739396,\n",
       " 41: 0.05253471927183669,\n",
       " 42: 0.05200334442566823,\n",
       " 43: 0.05686911716654804,\n",
       " 44: 0.051188672334524545,\n",
       " 45: 0.052204713570590956,\n",
       " 46: 0.05197615821474656,\n",
       " 47: 0.05456517101130691,\n",
       " 48: 0.05092777565185892,\n",
       " 49: 0.05201425375607805,\n",
       " 50: 0.05238291236085821,\n",
       " 51: 0.05059067477584443,\n",
       " 52: 0.051253522769360925,\n",
       " 53: 0.05247021390958727,\n",
       " 54: 0.049856944094398795,\n",
       " 55: 0.05237549056420041,\n",
       " 56: 0.05231771349818453,\n",
       " 57: 0.0579823005617139,\n",
       " 58: 0.05205900837620591,\n",
       " 59: 0.05269030220462708,\n",
       " 60: 0.0532736204932511,\n",
       " 61: 0.05460781755308891,\n",
       " 62: 0.051150894569860425,\n",
       " 63: 0.050812837909298775,\n",
       " 64: 0.049797294553729624,\n",
       " 65: 0.05162636222912545,\n",
       " 66: 0.05260464005418593,\n",
       " 67: 0.052391526280866095,\n",
       " 68: 0.05272134696307309,\n",
       " 69: 0.052316610013082104,\n",
       " 70: 0.05042544414523816,\n",
       " 71: 0.05051922610202755,\n",
       " 72: 0.05102768533607433,\n",
       " 73: 0.05300156003504759,\n",
       " 74: 0.05240839016918218,\n",
       " 75: 0.05359365348905684,\n",
       " 76: 0.052064132311916894,\n",
       " 77: 0.052700386881599656,\n",
       " 78: 0.05063209411712571,\n",
       " 79: 0.053728266689774616,\n",
       " 80: 0.0523417912606261,\n",
       " 81: 0.05241075253434486,\n",
       " 82: 0.05071522412343603,\n",
       " 83: 0.0523409140394853,\n",
       " 84: 0.05336498425979416,\n",
       " 85: 0.055373835512254756,\n",
       " 86: 0.052522826009894774,\n",
       " 87: 0.04842037456176446,\n",
       " 88: 0.051823725714824014,\n",
       " 89: 0.052195098377884254,\n",
       " 90: 0.052002053603395715,\n",
       " 91: 0.050781739372939026,\n",
       " 92: 0.05324519109894357,\n",
       " 93: 0.052524966012926826,\n",
       " 94: 0.05210813215603326,\n",
       " 95: 0.051805508633602226,\n",
       " 96: 0.05190335939821587,\n",
       " 97: 0.0532703923893809,\n",
       " 98: 0.052469117891014334,\n",
       " 99: 0.0516176486914258}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049856944094398795"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_score(pred):\n",
    "    if pred <= 0.0056:\n",
    "        pred = 0\n",
    "    elif pred >= 0.9944:\n",
    "        pred = 1\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008839051063222482 0.36092409673862275\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>coupon_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uuid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>0.009040</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.036575</td>\n",
       "      <td>0.009043</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.009040</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.008977</td>\n",
       "      <td>0.008977</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0.017314</td>\n",
       "      <td>0.017262</td>\n",
       "      <td>0.074247</td>\n",
       "      <td>0.040174</td>\n",
       "      <td>0.012876</td>\n",
       "      <td>0.009044</td>\n",
       "      <td>0.009044</td>\n",
       "      <td>0.353265</td>\n",
       "      <td>0.360924</td>\n",
       "      <td>0.009044</td>\n",
       "      <td>0.040174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0.016511</td>\n",
       "      <td>0.009175</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0.009131</td>\n",
       "      <td>0.009104</td>\n",
       "      <td>0.025483</td>\n",
       "      <td>0.009102</td>\n",
       "      <td>0.009044</td>\n",
       "      <td>0.009102</td>\n",
       "      <td>0.009044</td>\n",
       "      <td>0.179353</td>\n",
       "      <td>0.012870</td>\n",
       "      <td>0.009044</td>\n",
       "      <td>0.009076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>0.009040</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.055373</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>0.009153</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.009183</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.012972</td>\n",
       "      <td>0.027857</td>\n",
       "      <td>0.008846</td>\n",
       "      <td>0.009153</td>\n",
       "      <td>0.009078</td>\n",
       "      <td>0.009108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>0.009040</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009038</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.012692</td>\n",
       "      <td>0.009038</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.009101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0.020340</td>\n",
       "      <td>0.009133</td>\n",
       "      <td>0.023598</td>\n",
       "      <td>0.009133</td>\n",
       "      <td>0.019887</td>\n",
       "      <td>0.051629</td>\n",
       "      <td>0.020340</td>\n",
       "      <td>0.340421</td>\n",
       "      <td>0.032950</td>\n",
       "      <td>0.009446</td>\n",
       "      <td>0.009336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>0.009062</td>\n",
       "      <td>0.009034</td>\n",
       "      <td>0.009034</td>\n",
       "      <td>0.009034</td>\n",
       "      <td>0.009034</td>\n",
       "      <td>0.009034</td>\n",
       "      <td>0.009034</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.009034</td>\n",
       "      <td>0.009034</td>\n",
       "      <td>0.013615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "coupon_id        1         2         3         4         5         6   \\\n",
       "uuid                                                                    \n",
       "357        0.009040  0.009013  0.009013  0.009013  0.037037  0.009013   \n",
       "358        0.009040  0.009013  0.009013  0.009013  0.009013  0.009013   \n",
       "359        0.017314  0.017262  0.074247  0.040174  0.012876  0.009044   \n",
       "360        0.016511  0.009175  0.009013  0.009013  0.009013  0.009013   \n",
       "361        0.009131  0.009104  0.025483  0.009102  0.009044  0.009102   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "708        0.009040  0.009013  0.009013  0.009013  0.009013  0.009013   \n",
       "709        0.009153  0.009024  0.009024  0.009183  0.009024  0.012972   \n",
       "710        0.009040  0.009013  0.009013  0.009038  0.009013  0.009013   \n",
       "711        0.020340  0.009133  0.023598  0.009133  0.019887  0.051629   \n",
       "712        0.009062  0.009034  0.009034  0.009034  0.009034  0.009034   \n",
       "\n",
       "coupon_id        7         8         9         10        11  \n",
       "uuid                                                         \n",
       "357        0.009013  0.036575  0.009043  0.009013  0.009101  \n",
       "358        0.009013  0.008977  0.008977  0.009013  0.009101  \n",
       "359        0.009044  0.353265  0.360924  0.009044  0.040174  \n",
       "360        0.009013  0.008889  0.009013  0.009013  0.009101  \n",
       "361        0.009044  0.179353  0.012870  0.009044  0.009076  \n",
       "...             ...       ...       ...       ...       ...  \n",
       "708        0.009013  0.055373  0.009013  0.009013  0.009108  \n",
       "709        0.027857  0.008846  0.009153  0.009078  0.009108  \n",
       "710        0.009013  0.012692  0.009038  0.009013  0.009101  \n",
       "711        0.020340  0.340421  0.032950  0.009446  0.009336  \n",
       "712        0.009034  0.009147  0.009034  0.009034  0.013615  \n",
       "\n",
       "[356 rows x 11 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#テストデータの予測\n",
    "pred = model.predict(test_data.drop('uuid',axis=1))\n",
    "pred = pd.Series(pred, name='pred')\n",
    "pred = pred.apply(lambda x: round_score(x))\n",
    "print(pred.min(), pred.max())\n",
    "\n",
    "result = test_data.join(pred)[['uuid', 'coupon_id', 'pred']]\n",
    "result = result.pivot(index='uuid', columns='coupon_id', values='pred')\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# アンサンブル学習（XGBoost/LightGBM）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===============================================================\n",
    "#XGBoostによるモデル作成\n",
    "def xgb_train(tr_x, tr_y, va_x, va_y):\n",
    "    dtrain = xgb.DMatrix(tr_x, label=tr_y)\n",
    "    dvalid = xgb.DMatrix(va_x, label=va_y)\n",
    "    dtest = xgb.DMatrix(test_data.drop('uuid',axis=1))\n",
    "\n",
    "    # ハイパーパラメータの設定\n",
    "    params = {'objective': 'binary:logistic', \n",
    "              'eval_metric':'logloss',\n",
    "              'eta': 0.01,\n",
    "              'gamma': 0.0,\n",
    "              'alpha': 0.0,\n",
    "              'lambda': 1.0,\n",
    "              'min_child_weight': 8,\n",
    "              'max_depth': 6,\n",
    "              'subsample': 1.0,\n",
    "              'colsample_bytree': 0.8,\n",
    "              'random_state': 27,\n",
    "            }\n",
    "    num_round = 1000\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    model = xgb.train(params, \n",
    "                      dtrain, \n",
    "                      num_round, \n",
    "                      evals=watchlist,\n",
    "                      early_stopping_rounds=100,\n",
    "                      verbose_eval=50)\n",
    "\n",
    "    va_pred = model.predict(dvalid)\n",
    "    score = log_loss(va_y, va_pred)\n",
    "    \n",
    "    pred = model.predict(dtest)\n",
    "    pred = pd.Series(pred, name='pred')\n",
    "\n",
    "    return model, score, pred\n",
    "\n",
    "#===============================================================\n",
    "#LightGBMによるモデル作成\n",
    "def lgb_train(tr_x, tr_y, va_x, va_y):\n",
    "    params = {'objective': 'binary',\n",
    "             'metric': 'binary_logloss',\n",
    "             'seed': 118,\n",
    "             'lambda_l1': 0.00416566836241902,\n",
    "             'lambda_l2': 0.10371698288325823,\n",
    "             'num_leaves': 333,\n",
    "             'feature_fraction': 0.6873251818776734,\n",
    "             'bagging_fraction': 0.6363448284692337,\n",
    "             'bagging_freq': 10,\n",
    "             'min_child_samples': 17\n",
    "            }\n",
    "\n",
    "    num_round =1000\n",
    "    lgb_train = lgb.Dataset(tr_x, tr_y)\n",
    "    lgb_eval = lgb.Dataset(va_x, va_y)\n",
    "\n",
    "    model = lgb.train(params, \n",
    "                  lgb_train, \n",
    "                  verbose_eval=50,  # 50イテレーション毎に学習結果出力\n",
    "                  num_boost_round=num_round, \n",
    "                  early_stopping_rounds=100,\n",
    "                  valid_names=['train', 'valid'], \n",
    "                  valid_sets=[lgb_train, lgb_eval]\n",
    "                 )\n",
    "\n",
    "    va_pred = model.predict(va_x)\n",
    "    score = log_loss(va_y, va_pred)\n",
    "    \n",
    "    #テストデータの予測\n",
    "    pred = model.predict(test_data.drop('uuid',axis=1))\n",
    "    pred = pd.Series(pred, name='pred')\n",
    "    \n",
    "    return model, score, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_score(pred):\n",
    "    if pred <= 0.0056:\n",
    "        pred = 0\n",
    "    elif pred >= 0.9944:\n",
    "        pred = 1\n",
    "    return pred\n",
    "\n",
    "def pred_to_result(pred):\n",
    "    result = test_data.join(pred)[['uuid', 'coupon_id', 'pred']]\n",
    "    result = result.pivot(index='uuid', columns='coupon_id', values='pred')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.68372\teval-logloss:0.68362\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 100 rounds.\n",
      "[50]\ttrain-logloss:0.37434\teval-logloss:0.37121\n",
      "[100]\ttrain-logloss:0.22835\teval-logloss:0.22349\n",
      "[150]\ttrain-logloss:0.15124\teval-logloss:0.14551\n",
      "[200]\ttrain-logloss:0.10852\teval-logloss:0.10247\n",
      "[250]\ttrain-logloss:0.08456\teval-logloss:0.07830\n",
      "[300]\ttrain-logloss:0.07062\teval-logloss:0.06482\n",
      "[350]\ttrain-logloss:0.06238\teval-logloss:0.05736\n",
      "[400]\ttrain-logloss:0.05763\teval-logloss:0.05336\n",
      "[450]\ttrain-logloss:0.05460\teval-logloss:0.05131\n",
      "[500]\ttrain-logloss:0.05262\teval-logloss:0.04980\n",
      "[550]\ttrain-logloss:0.05130\teval-logloss:0.04929\n",
      "[600]\ttrain-logloss:0.05039\teval-logloss:0.04915\n",
      "[650]\ttrain-logloss:0.04968\teval-logloss:0.04917\n",
      "[700]\ttrain-logloss:0.04913\teval-logloss:0.04930\n",
      "Stopping. Best iteration:\n",
      "[624]\ttrain-logloss:0.05004\teval-logloss:0.04907\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[50]\ttrain's binary_logloss: 0.00989969\tvalid's binary_logloss: 0.0595462\n",
      "[100]\ttrain's binary_logloss: 0.00254294\tvalid's binary_logloss: 0.0726514\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttrain's binary_logloss: 0.0378827\tvalid's binary_logloss: 0.0486878\n"
     ]
    }
   ],
   "source": [
    "train_x = train_data.drop(['coupon_use_result','uuid'], axis=1)\n",
    "train_y = train_data[['coupon_use_result']]\n",
    "\n",
    "val_size = 4\n",
    "uuid_num = train_data['uuid'].nunique()\n",
    "train_uuid = int((uuid_num/val_size)*(val_size-1))\n",
    "filter_idx = (train_uuid*11)-1\n",
    "tr_x, va_x = train_x.iloc[:filter_idx], train_x.iloc[filter_idx:]\n",
    "tr_y, va_y = train_y.iloc[:filter_idx], train_y.iloc[filter_idx:]\n",
    "\n",
    "xgb_models = []\n",
    "lgb_models = []\n",
    "xgb_scores = []\n",
    "lgb_scores = []\n",
    "xgb_pred = []\n",
    "lgb_pred = []\n",
    "\n",
    "#アンサンブル学習\n",
    "xgb_models, xgb_scores, xgb_pred = xgb_train(tr_x, tr_y ,va_x, va_y)\n",
    "lgb_models, lgb_scores, lgb_pred = lgb_train(tr_x, tr_y ,va_x, va_y)\n",
    "weight = 0.5\n",
    "pred = (xgb_pred*weight + lgb_pred*(1-weight))\n",
    "pred = pred = pred.apply(lambda x: round_score(x))\n",
    "result = pred_to_result(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.000000\n",
       "1       0.000000\n",
       "2       0.000000\n",
       "3       0.000000\n",
       "4       0.011583\n",
       "          ...   \n",
       "3911    0.006289\n",
       "3912    0.016488\n",
       "3913    0.007353\n",
       "3914    0.007579\n",
       "3915    0.011415\n",
       "Name: pred, Length: 3916, dtype: float64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>coupon_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uuid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035996</td>\n",
       "      <td>0.025341</td>\n",
       "      <td>0.011235</td>\n",
       "      <td>0.011550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0.024849</td>\n",
       "      <td>0.018850</td>\n",
       "      <td>0.014964</td>\n",
       "      <td>0.017866</td>\n",
       "      <td>0.025920</td>\n",
       "      <td>0.018280</td>\n",
       "      <td>0.018263</td>\n",
       "      <td>0.392844</td>\n",
       "      <td>0.137140</td>\n",
       "      <td>0.015821</td>\n",
       "      <td>0.018025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010517</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0.013202</td>\n",
       "      <td>0.013327</td>\n",
       "      <td>0.011232</td>\n",
       "      <td>0.013517</td>\n",
       "      <td>0.014577</td>\n",
       "      <td>0.010570</td>\n",
       "      <td>0.013574</td>\n",
       "      <td>0.075725</td>\n",
       "      <td>0.012556</td>\n",
       "      <td>0.013928</td>\n",
       "      <td>0.013928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>708</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>0.007926</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006235</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013888</td>\n",
       "      <td>0.029290</td>\n",
       "      <td>0.012569</td>\n",
       "      <td>0.008953</td>\n",
       "      <td>0.009179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>710</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>0.048702</td>\n",
       "      <td>0.012643</td>\n",
       "      <td>0.015624</td>\n",
       "      <td>0.023723</td>\n",
       "      <td>0.029219</td>\n",
       "      <td>0.012699</td>\n",
       "      <td>0.024976</td>\n",
       "      <td>0.287124</td>\n",
       "      <td>0.052808</td>\n",
       "      <td>0.012818</td>\n",
       "      <td>0.014882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.006366</td>\n",
       "      <td>0.006321</td>\n",
       "      <td>0.006746</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>0.006157</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>0.016488</td>\n",
       "      <td>0.007353</td>\n",
       "      <td>0.007579</td>\n",
       "      <td>0.011415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "coupon_id        1         2         3         4         5         6   \\\n",
       "uuid                                                                    \n",
       "357        0.000000  0.000000  0.000000  0.000000  0.011583  0.000000   \n",
       "358        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "359        0.024849  0.018850  0.014964  0.017866  0.025920  0.018280   \n",
       "360        0.000000  0.010092  0.000000  0.000000  0.000000  0.000000   \n",
       "361        0.013202  0.013327  0.011232  0.013517  0.014577  0.010570   \n",
       "...             ...       ...       ...       ...       ...       ...   \n",
       "708        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "709        0.007926  0.000000  0.000000  0.006235  0.000000  0.000000   \n",
       "710        0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "711        0.048702  0.012643  0.015624  0.023723  0.029219  0.012699   \n",
       "712        0.007133  0.006366  0.006321  0.006746  0.006169  0.006157   \n",
       "\n",
       "coupon_id        7         8         9         10        11  \n",
       "uuid                                                         \n",
       "357        0.000000  0.041989  0.000000  0.000000  0.000000  \n",
       "358        0.000000  0.035996  0.025341  0.011235  0.011550  \n",
       "359        0.018263  0.392844  0.137140  0.015821  0.018025  \n",
       "360        0.000000  0.010517  0.000000  0.000000  0.000000  \n",
       "361        0.013574  0.075725  0.012556  0.013928  0.013928  \n",
       "...             ...       ...       ...       ...       ...  \n",
       "708        0.000000  0.027986  0.000000  0.000000  0.007908  \n",
       "709        0.013888  0.029290  0.012569  0.008953  0.009179  \n",
       "710        0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "711        0.024976  0.287124  0.052808  0.012818  0.014882  \n",
       "712        0.006289  0.016488  0.007353  0.007579  0.011415  \n",
       "\n",
       "[356 rows x 11 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04931323879549301 0.04868782829132765\n",
      "0.0 0.3928439470306875\n"
     ]
    }
   ],
   "source": [
    "print(xgb_scores, lgb_scores)\n",
    "print(pred.min(), pred.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38168117"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4040067200215342"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('/Users/atsushisato/git_clone/ai_quest_season2/models/model.csv',header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1619"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optunaによるパラメータ調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'binary',\n",
       " 'metric': 'binary_logloss',\n",
       " 'seed': 71,\n",
       " 'feature_pre_filter': False,\n",
       " 'lambda_l1': 1.0075794784727784e-08,\n",
       " 'lambda_l2': 0.023033986719849988,\n",
       " 'num_leaves': 317,\n",
       " 'feature_fraction': 0.7,\n",
       " 'bagging_fraction': 0.4983467582046316,\n",
       " 'bagging_freq': 4,\n",
       " 'min_data_in_leaf': 22,\n",
       " 'min_child_samples': 20}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータ調整用\n",
    "\n",
    "# prediction = np.rint(model.predict(va_x, num_iteration=model.best_iteration))\n",
    "# accuracy = accuracy_score(va_y, prediction)\n",
    "# best_params = model.params\n",
    "# print(\"Best params:\", display(best_params)\n",
    "# print(\"  Accuracy = {}\".format(accuracy))\n",
    "# print(\"  Params: \")\n",
    "# for key, value in best_params.items():\n",
    "#     print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting': 'gbdt',\n",
    "        'learning_rate': 0.05,\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 512),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 0, 10),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'seed': 0,\n",
    "        'verbosity': -1,\n",
    "    }\n",
    "    gbm = lgb.train(param, \n",
    "                    lgb_train, \n",
    "#                     valid_sets=lgb_eval,\n",
    "                    verbose_eval=False, \n",
    "                    num_boost_round=num_round, \n",
    "#                     early_stopping_rounds=50\n",
    "                   )\n",
    "    y_prob = gbm.predict(va_x)\n",
    "    y_pred = np.round(y_prob)\n",
    "    return roc_auc_score(\n",
    "        np.round(va_y.values),\n",
    "        np.round(y_pred)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_data.drop(['coupon_use_result','uuid'], axis=1)\n",
    "train_y = train_data[['coupon_use_result']]\n",
    "\n",
    "val_size = 4\n",
    "uuid_num = train_data['uuid'].nunique()\n",
    "train_uuid = int((uuid_num/val_size)*(val_size-1))\n",
    "filter_idx = (train_uuid*11)-1\n",
    "tr_x, va_x = train_x.iloc[:filter_idx], train_x.iloc[filter_idx:]\n",
    "tr_y, va_y = train_y.iloc[:filter_idx], train_y.iloc[filter_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# study = optuna.create_study()\n",
    "# study.optimize(xgb_objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Best trial:', display(study.best_trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-01-10 17:16:49,336]\u001b[0m A new study created in memory with name: no-name-4428f7ca-bb90-49ec-8906-3167c7ec4418\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:16:49,822]\u001b[0m Trial 0 finished with value: 0.4989572471324296 and parameters: {'lambda_l1': 2.230483819354161e-06, 'lambda_l2': 0.7466146658073363, 'num_leaves': 466, 'feature_fraction': 0.6891702640405284, 'bagging_fraction': 0.7251771207195571, 'bagging_freq': 8, 'min_child_samples': 93}. Best is trial 0 with value: 0.4989572471324296.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:16:49,937]\u001b[0m Trial 1 finished with value: 0.5 and parameters: {'lambda_l1': 8.25214730452868, 'lambda_l2': 0.32057059962204465, 'num_leaves': 317, 'feature_fraction': 0.7038675542158336, 'bagging_fraction': 0.5790332692302901, 'bagging_freq': 2, 'min_child_samples': 54}. Best is trial 1 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:16:50,511]\u001b[0m Trial 2 finished with value: 0.4994786235662148 and parameters: {'lambda_l1': 3.791259876969217e-05, 'lambda_l2': 2.0725431546822375e-08, 'num_leaves': 376, 'feature_fraction': 0.8213109146315727, 'bagging_fraction': 0.45203225735662816, 'bagging_freq': 0, 'min_child_samples': 42}. Best is trial 1 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:16:51,378]\u001b[0m Trial 3 finished with value: 0.4994786235662148 and parameters: {'lambda_l1': 0.002197282590760803, 'lambda_l2': 6.565271824999493e-08, 'num_leaves': 96, 'feature_fraction': 0.7772288887511358, 'bagging_fraction': 0.6600770018028674, 'bagging_freq': 7, 'min_child_samples': 48}. Best is trial 1 with value: 0.5.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:16:51,716]\u001b[0m Trial 4 finished with value: 0.5494786235662149 and parameters: {'lambda_l1': 0.059894240326589916, 'lambda_l2': 1.0302168677111394e-05, 'num_leaves': 382, 'feature_fraction': 0.9760627682340816, 'bagging_fraction': 0.957495412018543, 'bagging_freq': 7, 'min_child_samples': 14}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:16:52,103]\u001b[0m Trial 5 finished with value: 0.4994786235662148 and parameters: {'lambda_l1': 0.5411771655267101, 'lambda_l2': 1.4037044763447245e-07, 'num_leaves': 373, 'feature_fraction': 0.807621792018265, 'bagging_fraction': 0.5486862452701761, 'bagging_freq': 1, 'min_child_samples': 31}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:16:52,529]\u001b[0m Trial 6 finished with value: 0.5 and parameters: {'lambda_l1': 0.0001009199014892158, 'lambda_l2': 0.00028918590880014047, 'num_leaves': 435, 'feature_fraction': 0.6675603824369081, 'bagging_fraction': 0.5998159249247139, 'bagging_freq': 6, 'min_child_samples': 98}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:16:52,719]\u001b[0m Trial 7 finished with value: 0.5 and parameters: {'lambda_l1': 1.6430512992846664, 'lambda_l2': 8.014551780841069e-05, 'num_leaves': 171, 'feature_fraction': 0.43190311187640784, 'bagging_fraction': 0.9344217643122104, 'bagging_freq': 6, 'min_child_samples': 83}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:16:53,194]\u001b[0m Trial 8 finished with value: 0.4994786235662148 and parameters: {'lambda_l1': 0.09562354508793425, 'lambda_l2': 0.04939336627456834, 'num_leaves': 393, 'feature_fraction': 0.8792145163667887, 'bagging_fraction': 0.6673536129702133, 'bagging_freq': 7, 'min_child_samples': 55}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:16:53,755]\u001b[0m Trial 9 finished with value: 0.5 and parameters: {'lambda_l1': 1.3728021927480612e-08, 'lambda_l2': 4.837446892349607e-07, 'num_leaves': 169, 'feature_fraction': 0.7059290607060249, 'bagging_fraction': 0.6560032376220954, 'bagging_freq': 7, 'min_child_samples': 54}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:16:54,205]\u001b[0m Trial 10 finished with value: 0.4994786235662148 and parameters: {'lambda_l1': 0.010153372401234276, 'lambda_l2': 1.4413922332786136e-05, 'num_leaves': 511, 'feature_fraction': 0.9881609662841089, 'bagging_fraction': 0.9861995395544089, 'bagging_freq': 10, 'min_child_samples': 5}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:16:54,338]\u001b[0m Trial 11 finished with value: 0.5 and parameters: {'lambda_l1': 9.775839627174733, 'lambda_l2': 0.016624762426792096, 'num_leaves': 287, 'feature_fraction': 0.5340268252628688, 'bagging_fraction': 0.8498370786384244, 'bagging_freq': 3, 'min_child_samples': 7}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:16:55,079]\u001b[0m Trial 12 finished with value: 0.4994786235662148 and parameters: {'lambda_l1': 0.09107223968008964, 'lambda_l2': 7.689967862846079, 'num_leaves': 286, 'feature_fraction': 0.9920332823564366, 'bagging_fraction': 0.8127182031442954, 'bagging_freq': 3, 'min_child_samples': 19}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:16:55,182]\u001b[0m Trial 13 finished with value: 0.5 and parameters: {'lambda_l1': 7.844769278280773, 'lambda_l2': 3.3482118978538734e-06, 'num_leaves': 312, 'feature_fraction': 0.5668061882938922, 'bagging_fraction': 0.44064482459355536, 'bagging_freq': 3, 'min_child_samples': 71}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:16:55,968]\u001b[0m Trial 14 finished with value: 0.5 and parameters: {'lambda_l1': 0.015578198842376162, 'lambda_l2': 0.004903095901611538, 'num_leaves': 217, 'feature_fraction': 0.9233080530239405, 'bagging_fraction': 0.5262037267185102, 'bagging_freq': 10, 'min_child_samples': 64}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:16:56,392]\u001b[0m Trial 15 finished with value: 0.5 and parameters: {'lambda_l1': 8.970092022631807, 'lambda_l2': 0.001237162827771142, 'num_leaves': 361, 'feature_fraction': 0.5729576837894155, 'bagging_fraction': 0.7684055395114942, 'bagging_freq': 4, 'min_child_samples': 24}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:16:56,607]\u001b[0m Trial 16 finished with value: 0.5 and parameters: {'lambda_l1': 0.25592904297383423, 'lambda_l2': 9.368460465441666, 'num_leaves': 3, 'feature_fraction': 0.4594778551688412, 'bagging_fraction': 0.8823303946706992, 'bagging_freq': 1, 'min_child_samples': 35}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:16:57,450]\u001b[0m Trial 17 finished with value: 0.5 and parameters: {'lambda_l1': 0.0013808654070704687, 'lambda_l2': 2.679263755548631e-06, 'num_leaves': 53, 'feature_fraction': 0.4134823019600732, 'bagging_fraction': 0.9076153441105396, 'bagging_freq': 9, 'min_child_samples': 34}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:16:58,230]\u001b[0m Trial 18 finished with value: 0.5494786235662149 and parameters: {'lambda_l1': 0.000518034707556767, 'lambda_l2': 2.205530175723705e-06, 'num_leaves': 21, 'feature_fraction': 0.497752905969679, 'bagging_fraction': 0.9962443060462723, 'bagging_freq': 9, 'min_child_samples': 14}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:00,235]\u001b[0m Trial 19 finished with value: 0.4994786235662148 and parameters: {'lambda_l1': 7.197840144477356e-06, 'lambda_l2': 6.592934231045706e-05, 'num_leaves': 508, 'feature_fraction': 0.5011578127766363, 'bagging_fraction': 0.9947316117617928, 'bagging_freq': 9, 'min_child_samples': 13}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:01,937]\u001b[0m Trial 20 finished with value: 0.5 and parameters: {'lambda_l1': 1.268251505727782e-07, 'lambda_l2': 8.231653585635578e-07, 'num_leaves': 230, 'feature_fraction': 0.627184552548917, 'bagging_fraction': 0.9539401888961897, 'bagging_freq': 5, 'min_child_samples': 18}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:02,949]\u001b[0m Trial 21 finished with value: 0.4994786235662148 and parameters: {'lambda_l1': 4.421539325266757e-08, 'lambda_l2': 9.447829387165727e-07, 'num_leaves': 226, 'feature_fraction': 0.6438546513948032, 'bagging_fraction': 0.9573409077782862, 'bagging_freq': 5, 'min_child_samples': 16}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:03,485]\u001b[0m Trial 22 finished with value: 0.5 and parameters: {'lambda_l1': 0.0006918979174185913, 'lambda_l2': 1.8359132207563505e-05, 'num_leaves': 436, 'feature_fraction': 0.7661669752300777, 'bagging_fraction': 0.509888469715275, 'bagging_freq': 9, 'min_child_samples': 62}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:04,261]\u001b[0m Trial 23 finished with value: 0.4994786235662148 and parameters: {'lambda_l1': 0.012880880537594732, 'lambda_l2': 0.007774862631498272, 'num_leaves': 324, 'feature_fraction': 0.5142660359323581, 'bagging_fraction': 0.8174094847143584, 'bagging_freq': 8, 'min_child_samples': 7}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:05,100]\u001b[0m Trial 24 finished with value: 0.5385297184567258 and parameters: {'lambda_l1': 0.00018000668141659413, 'lambda_l2': 0.0007283786633342031, 'num_leaves': 154, 'feature_fraction': 0.5525369360106458, 'bagging_fraction': 0.8575315455153408, 'bagging_freq': 4, 'min_child_samples': 7}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:05,880]\u001b[0m Trial 25 finished with value: 0.4994786235662148 and parameters: {'lambda_l1': 0.00013800914743238658, 'lambda_l2': 0.0006487347506908835, 'num_leaves': 104, 'feature_fraction': 0.5946301587222429, 'bagging_fraction': 0.9960097118142566, 'bagging_freq': 6, 'min_child_samples': 26}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:06,253]\u001b[0m Trial 26 finished with value: 0.5494786235662149 and parameters: {'lambda_l1': 1.2022616216886636e-05, 'lambda_l2': 1.1557573947828457e-05, 'num_leaves': 4, 'feature_fraction': 0.4774773146142428, 'bagging_fraction': 0.862255881027496, 'bagging_freq': 4, 'min_child_samples': 11}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:06,780]\u001b[0m Trial 27 finished with value: 0.5 and parameters: {'lambda_l1': 2.243722926633738e-06, 'lambda_l2': 1.01131407228634e-05, 'num_leaves': 21, 'feature_fraction': 0.40138521954578094, 'bagging_fraction': 0.9113801504651078, 'bagging_freq': 8, 'min_child_samples': 12}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:07,389]\u001b[0m Trial 28 finished with value: 0.49061522419186654 and parameters: {'lambda_l1': 1.0625888439121895e-05, 'lambda_l2': 6.323809221327715e-05, 'num_leaves': 75, 'feature_fraction': 0.46709221416484953, 'bagging_fraction': 0.7774648819538766, 'bagging_freq': 4, 'min_child_samples': 25}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:08,164]\u001b[0m Trial 29 finished with value: 0.4994786235662148 and parameters: {'lambda_l1': 3.169649444617091e-07, 'lambda_l2': 1.5403916234108368e-07, 'num_leaves': 34, 'feature_fraction': 0.48471990718928726, 'bagging_fraction': 0.7228795355791937, 'bagging_freq': 8, 'min_child_samples': 42}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:08,898]\u001b[0m Trial 30 finished with value: 0.4994786235662148 and parameters: {'lambda_l1': 8.328660608629147e-07, 'lambda_l2': 4.11361081815484e-06, 'num_leaves': 124, 'feature_fraction': 0.9246741379196246, 'bagging_fraction': 0.9697251654364963, 'bagging_freq': 10, 'min_child_samples': 21}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:09,405]\u001b[0m Trial 31 finished with value: 0.5494786235662149 and parameters: {'lambda_l1': 2.689692795965989e-05, 'lambda_l2': 0.00021376083781940732, 'num_leaves': 5, 'feature_fraction': 0.5360961447531212, 'bagging_fraction': 0.8759086963986498, 'bagging_freq': 4, 'min_child_samples': 6}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:10,036]\u001b[0m Trial 32 finished with value: 0.4994786235662148 and parameters: {'lambda_l1': 2.069799979617352e-05, 'lambda_l2': 0.00024924486945084463, 'num_leaves': 12, 'feature_fraction': 0.4420465961168966, 'bagging_fraction': 0.8990745450101667, 'bagging_freq': 5, 'min_child_samples': 11}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:10,889]\u001b[0m Trial 33 finished with value: 0.4994786235662148 and parameters: {'lambda_l1': 1.538003843691296e-06, 'lambda_l2': 1.754521793782045e-05, 'num_leaves': 55, 'feature_fraction': 0.6164197538063797, 'bagging_fraction': 0.8585878715776152, 'bagging_freq': 2, 'min_child_samples': 13}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:11,161]\u001b[0m Trial 34 finished with value: 0.5489572471324297 and parameters: {'lambda_l1': 5.091887614648583e-05, 'lambda_l2': 1.7910596984814507e-08, 'num_leaves': 5, 'feature_fraction': 0.5241144628228724, 'bagging_fraction': 0.9324271099941798, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:11,947]\u001b[0m Trial 35 finished with value: 0.4921793534932221 and parameters: {'lambda_l1': 3.8948282903705815e-06, 'lambda_l2': 6.778570764012301e-05, 'num_leaves': 71, 'feature_fraction': 0.7155179938266268, 'bagging_fraction': 0.7622338668545816, 'bagging_freq': 6, 'min_child_samples': 29}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:12,750]\u001b[0m Trial 36 finished with value: 0.4994786235662148 and parameters: {'lambda_l1': 0.004588308874561917, 'lambda_l2': 2.4571248496759655e-07, 'num_leaves': 479, 'feature_fraction': 0.48473191804226456, 'bagging_fraction': 0.8139691035902042, 'bagging_freq': 2, 'min_child_samples': 42}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:13,535]\u001b[0m Trial 37 finished with value: 0.5 and parameters: {'lambda_l1': 0.000830342497760032, 'lambda_l2': 2.4522015498321095e-06, 'num_leaves': 128, 'feature_fraction': 0.5942707926407313, 'bagging_fraction': 0.8774448082363221, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:14,096]\u001b[0m Trial 38 finished with value: 0.4994786235662148 and parameters: {'lambda_l1': 0.000347455582627917, 'lambda_l2': 6.083690285325102e-08, 'num_leaves': 405, 'feature_fraction': 0.7422381626349255, 'bagging_fraction': 0.9524930229229974, 'bagging_freq': 7, 'min_child_samples': 19}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:15,041]\u001b[0m Trial 39 finished with value: 0.4994786235662148 and parameters: {'lambda_l1': 3.8083738661528015e-05, 'lambda_l2': 0.00011950740986168264, 'num_leaves': 347, 'feature_fraction': 0.6646431494561021, 'bagging_fraction': 0.9330438254221363, 'bagging_freq': 6, 'min_child_samples': 35}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:15,683]\u001b[0m Trial 40 finished with value: 0.4989572471324296 and parameters: {'lambda_l1': 0.04449490492142749, 'lambda_l2': 0.002239604642199602, 'num_leaves': 34, 'feature_fraction': 0.41969409089799414, 'bagging_fraction': 0.8422087260129417, 'bagging_freq': 3, 'min_child_samples': 88}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:16,310]\u001b[0m Trial 41 finished with value: 0.5494786235662149 and parameters: {'lambda_l1': 5.4325679716598584e-05, 'lambda_l2': 1.1728483795518414e-08, 'num_leaves': 15, 'feature_fraction': 0.5233007290465684, 'bagging_fraction': 0.9278809024305078, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:17,207]\u001b[0m Trial 42 finished with value: 0.5494786235662149 and parameters: {'lambda_l1': 1.945151242765841e-05, 'lambda_l2': 1.0180263736407606e-08, 'num_leaves': 86, 'feature_fraction': 0.541157983650162, 'bagging_fraction': 0.9818719072754956, 'bagging_freq': 4, 'min_child_samples': 12}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:17,544]\u001b[0m Trial 43 finished with value: 0.49582898852971846 and parameters: {'lambda_l1': 1.1666330529030332e-05, 'lambda_l2': 1.1548005094013376e-08, 'num_leaves': 89, 'feature_fraction': 0.5378007567527964, 'bagging_fraction': 0.8960685186043398, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:18,375]\u001b[0m Trial 44 finished with value: 0.4994786235662148 and parameters: {'lambda_l1': 5.1971018134398925e-05, 'lambda_l2': 5.6711606094202695e-08, 'num_leaves': 42, 'feature_fraction': 0.5801300362378058, 'bagging_fraction': 0.9959114314976912, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:19,825]\u001b[0m Trial 45 finished with value: 0.4994786235662148 and parameters: {'lambda_l1': 0.00010065428428820904, 'lambda_l2': 0.31740696939989327, 'num_leaves': 186, 'feature_fraction': 0.8253175584116252, 'bagging_fraction': 0.9205646581804202, 'bagging_freq': 4, 'min_child_samples': 9}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:20,049]\u001b[0m Trial 46 finished with value: 0.4994786235662148 and parameters: {'lambda_l1': 7.576725923890867e-07, 'lambda_l2': 3.107932428104616e-05, 'num_leaves': 4, 'feature_fraction': 0.4570722470788181, 'bagging_fraction': 0.4026759389990864, 'bagging_freq': 2, 'min_child_samples': 23}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:20,206]\u001b[0m Trial 47 finished with value: 0.5 and parameters: {'lambda_l1': 2.001099852923101, 'lambda_l2': 3.678485305449402e-07, 'num_leaves': 65, 'feature_fraction': 0.4955718874237535, 'bagging_fraction': 0.9758259245540245, 'bagging_freq': 7, 'min_child_samples': 16}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:20,955]\u001b[0m Trial 48 finished with value: 0.5 and parameters: {'lambda_l1': 1.9510959455965514e-05, 'lambda_l2': 3.819118515925472e-08, 'num_leaves': 109, 'feature_fraction': 0.555609159347643, 'bagging_fraction': 0.8759223807385599, 'bagging_freq': 3, 'min_child_samples': 30}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n",
      "\u001b[32m[I 2021-01-10 17:17:21,758]\u001b[0m Trial 49 finished with value: 0.5 and parameters: {'lambda_l1': 0.0026738137008422485, 'lambda_l2': 0.00021695979176229792, 'num_leaves': 255, 'feature_fraction': 0.529503710416586, 'bagging_fraction': 0.8367100394020276, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 4 with value: 0.5494786235662149.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "lgb_train = lgb.Dataset(tr_x, tr_y)\n",
    "lgb_eval = lgb.Dataset(va_x, va_y)\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 50\n"
     ]
    }
   ],
   "source": [
    "#ベストパラメータ\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "#Number of finished trials: 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lambda_l1': 0.059894240326589916,\n",
       " 'lambda_l2': 1.0302168677111394e-05,\n",
       " 'num_leaves': 382,\n",
       " 'feature_fraction': 0.9760627682340816,\n",
       " 'bagging_fraction': 0.957495412018543,\n",
       " 'bagging_freq': 7,\n",
       " 'min_child_samples': 14}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial: None\n"
     ]
    }
   ],
   "source": [
    "print('Best trial:', display(study.best_trial.params))\n",
    "\n",
    "#初回\n",
    "# {'lambda_l1': 5.204866804465978e-08,\n",
    "#  'lambda_l2': 3.133667635701077e-05,\n",
    "#  'num_leaves': 317,\n",
    "#  'feature_fraction': 0.848640913268004,\n",
    "#  'bagging_fraction': 0.4983467582046316,\n",
    "#  'bagging_freq': 4,\n",
    "#  'min_child_samples': 22}\n",
    "# Best trial: None\n",
    "\n",
    "#2回目\n",
    "# {'lambda_l1': 0.00416566836241902,\n",
    "#  'lambda_l2': 0.10371698288325823,\n",
    "#  'num_leaves': 333,\n",
    "#  'feature_fraction': 0.6873251818776734,\n",
    "#  'bagging_fraction': 0.6363448284692337,\n",
    "#  'bagging_freq': 10,\n",
    "#  'min_child_samples': 17}\n",
    "# Best trial: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# グリッドサーチによるパラメータ調整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベースラインのパラメータ\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic',\n",
    "    'eta': 0.1,\n",
    "    'gamma': 0.0,\n",
    "    'alpha': 0.0,\n",
    "    'lambda': 1.0,\n",
    "    'min_child_weight': 1,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': 71,\n",
    "}\n",
    "\n",
    "def optimize(trials):\n",
    "    # パラメータの探索範囲\n",
    "    param_space = {\n",
    "        'min_child_weight': hp.loguniform('min_child_weight', np.log(0.1), np.log(10)),\n",
    "        'max_depth': hp.quniform('max_depth', 3, 9, 1),\n",
    "        'subsample': hp.quniform('subsample', 0.6, 0.95, 0.05),\n",
    "        'colsample_bytree': hp.quniform('subsample', 0.6, 0.95, 0.05),\n",
    "        'gamma': hp.loguniform('gamma', np.log(1e-8), np.log(1.0)),\n",
    "        # 余裕があればalpha, lambdaも調整する\n",
    "        # 'alpha' : hp.loguniform('alpha', np.log(1e-8), np.log(1.0)),\n",
    "        # 'lambda' : hp.loguniform('lambda', np.log(1e-6), np.log(10.0)),\n",
    "    }\n",
    "    \n",
    "    best = fmin(score, param_space, algo=tpe.suggest, trials=trials, max_evals=0)\n",
    "    \n",
    "def score(params):\n",
    "    dtrain = xgb.DMatrix(tr_x, label=tr_y)\n",
    "    dvalid = xgb.DMatrix(va_x, label=va_y)\n",
    "    dtest = xgb.DMatrix(test_data.drop('uuid',axis=1))\n",
    "\n",
    "    num_round = 1000\n",
    "\n",
    "    scores= []\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    model = xgb.train(params, \n",
    "                      dtrain, \n",
    "                      num_round, \n",
    "                      evals=watchlist,\n",
    "                      early_stopping_rounds=50,\n",
    "                      verbose_eval=50\n",
    "                     )\n",
    "\n",
    "    va_pred = model.predict(dvalid)\n",
    "    score = log_loss(va_y, va_pred)\n",
    "    scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:0.35728\teval-rmse:0.35756                               \n",
      "\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.               \n",
      "\n",
      "[50]\ttrain-rmse:0.03417\teval-rmse:0.10486                              \n",
      "\n",
      "Stopping. Best iteration:                                              \n",
      "[13]\ttrain-rmse:0.07617\teval-rmse:0.10017\n",
      "\n",
      "\n",
      "  0%|          | 0/9223372036854775807 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "job exception: cannot convert dictionary update sequence element #0 to a sequence\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9223372036854775807 [00:00<?, ?trial/s, best loss=?]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot convert dictionary update sequence element #0 to a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-37c728e2ed31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-70-1b2256ccaa48>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(trials)\u001b[0m\n\u001b[1;32m     27\u001b[0m     }\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             \u001b[0mearly_stop_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m             \u001b[0mtrials_save_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials_save_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m         )\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0mshow_progressbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progressbar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m             \u001b[0mearly_stop_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stop_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0mtrials_save_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials_save_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         )\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0mdict_rval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"status\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSTATUS_OK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m             \u001b[0mdict_rval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m             \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_rval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"status\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSTATUS_STRINGS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot convert dictionary update sequence element #0 to a sequence"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "optimize(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_feature_together(train, test, num_cols):\n",
    "#     train, test = transform_box_cox(train, test, num_cols)\n",
    "#     return train, test\n",
    "\n",
    "# # issue 14 Box-Cox変換\n",
    "# def transform_box_cox(train, test, column):\n",
    "#     pt = PowerTransformer(method='box-cox')\n",
    "#     pt.fit(train[column])\n",
    "\n",
    "#     # 変換後のデータで各列を置換\n",
    "#     train[column] = pt.transform(train[column])\n",
    "#     test[column] = pt.transform(test[column])\n",
    "\n",
    "#特徴量作成（train_dataとtest_dataで同一の処理が必要）\n",
    "#変換するカラム\n",
    "# num_cols = ['all_purchase_price']\n",
    "# train_data, test_data = create_feature_together(train_data, test_data, num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_x, va_x, tr_y, va_y = train_test_split(train_x, train_y,\n",
    "#                                           test_size=0.25, random_state=71, shuffle=True)\n",
    "# kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "# for tr_idx, va_idx in kf.split(train_x):\n",
    "#     tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "#     tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
